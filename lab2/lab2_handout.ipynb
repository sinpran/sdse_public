{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ad26da",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Lab 2 <br><br> Gradient descent and <br> Stochastic Gradient Descent </center></h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b950901d",
   "metadata": {},
   "source": [
    "Note: The format for the report is as a Jupyter Notebook. Please include the section number and SIDs of the members of your group in the results dictionary. A single notebook should be submitted as a group submission in Gradescope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    'section_number' : 0, # enter your student id here\n",
    "    'SIDs': [0,0] # enter the SIDs for the group members\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7366e6",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf83570",
   "metadata": {},
   "source": [
    "In this lab we will explore the gradient descent and stochastic gradient descent algorithms for solving a least squares optimization problem. The setup is as follows. We wish to model a process with scalar input $X$ and scalar output $Y$. Both of these are real-valued random variables; their sample spaces are the real line. The joint distribution of $X$ and $Y$ is given as:\n",
    "\\begin{align*}\n",
    "X &\\sim \\mathcal{U}(0,1) \\\\\n",
    "Y|X\\!=\\!x &\\sim \\mathcal{N}( \\theta_0 + \\theta_1 x ,\\sigma^2_\\epsilon)\n",
    "\\end{align*}\n",
    "This definition of $Y|X\\!=\\!x$ is equivalent to,\n",
    "\\begin{equation*}\n",
    "Y = \\theta_0 + \\theta_1 X + \\epsilon\n",
    "\\end{equation*}\n",
    "with $\\epsilon\\sim\\mathcal{N}(0,\\sigma^2_\\epsilon)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd43a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edcb6d4",
   "metadata": {},
   "source": [
    "# 1. Sampling the joint distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753ef4b",
   "metadata": {},
   "source": [
    "We will first construct a synthetic dataset by sampling  from $(X,Y)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3aff5",
   "metadata": {},
   "source": [
    "## (1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d27b6",
   "metadata": {},
   "source": [
    "Write a function called `sampleXY` that produces a dataset $\\{(x_n,y_n)\\}_N$ of iid samples from $(X,Y)$, given arguments $N$, $\\theta_0$, $\\theta_1$, and $\\sigma^2_\\epsilon$. The output of this function should be a numpy array with shape = $(N,2)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleXY(N, theta0, theta1, sigma2_eps):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 40\n",
    "theta0=0.2\n",
    "theta1=-0.4\n",
    "sigma_eps=np.sqrt(0.0049)\n",
    "XYsamp = sampleXY(N, theta0, theta1, sigma_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c49f8",
   "metadata": {},
   "source": [
    "Run `sampleXY` with $N\\!=\\!40$, $\\theta_0\\!=\\!0.2$, $\\theta_1\\!=\\!-0.4$, and $\\sigma^2_\\epsilon\\!=\\!0.0049$ and assign the result to the variable `XYsamp`. Create a plot showing the line $y=\\theta_0 + \\theta_1 x$, overlaid with a scatter plot of `XYsamp`. The plot should have labels on the x and y axes. (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af952ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ce29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig1'] = fig1\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314585ca",
   "metadata": {},
   "source": [
    "We will now overwrite the data you sampled with another dataset contained in the file `1d_data.pickle`. This is so the results are predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./1d_data.pickle', 'rb') as file:\n",
    "    XYsamp = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c4147",
   "metadata": {},
   "source": [
    "# 2. Least squares linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36327370",
   "metadata": {},
   "source": [
    "We will now produce estimates of $\\theta_0$ and $\\theta_1$ corresponding to the least squares estimate of a straigt line fitted to `XYsamp`. The model in this case is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat y(x) = h(x;\\hat\\theta_0,\\hat\\theta_1) =  \\hat\\theta_0 +  \\hat\\theta_1 x\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "The error for each sample is the squared difference between the sampled and modeled values:\n",
    "\\begin{equation*}\n",
    "\\ell_n(\\hat\\theta_0,\\hat\\theta_1) = \\left( \\hat y(x_n) - y_n \\right)^2 = (\\hat \\theta_0 + \\hat \\theta_1 \\: x_n - y_n)^2 \n",
    "\\end{equation*}\n",
    "\n",
    "Notice a slightly confusing but crucial point: We are considering the error for the $n$'th sample ($\\ell_n$) as a function of the parameter estimates $\\hat\\theta_0$ and $\\hat\\theta_1$, with \"parameters\" $x_n$ and $y_n$, whereas the model $h$ is a function of $x$ with parameters $\\hat\\theta_0$ and $\\hat\\theta_1$. The roles of \"input\" and \"parameter\" are inverted. \n",
    "\n",
    "We define the matrix $\\Phi\\in\\mathbb{R}^{N\\times 2}$ such that the model can be written in matrix form:\n",
    "\\begin{equation*}\n",
    "\\mathbf{\\hat Y} = \\Phi \\: \\hat\\theta \n",
    "\\end{equation*}\n",
    "where \n",
    "\\begin{equation*}\n",
    "\\hat\\theta = \\begin{bmatrix}\\hat\\theta_0 \\\\ \\hat\\theta_1 \\end{bmatrix} \\hspace{3em} \\text{and} \\hspace{3em}\n",
    "\\mathbf{\\hat Y} = \\begin{bmatrix} \\hat y(x_1) \\\\ \\vdots \\\\ \\hat y(x_N) \\end{bmatrix} \n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "The total loss for candidate parameters $\\hat\\theta_0$ and $\\hat\\theta_1$ is defined as the sum of the losses for each sample:\n",
    "\\begin{equation*}\n",
    "L(\\hat\\theta_0, \\hat\\theta_1) \\;=\\; \\sum_{n=1}^{N} \\ell_n(\\hat\\theta_0, \\hat\\theta_1) \\;=\\; \\sum_{n=1}^{N} \\left( \\hat y(x_n) - y_n \\right)^2 \\;=\\; \\lvert\\lvert \\Phi \\hat\\theta-\\mathbf{Y} \\rvert\\rvert^2_2\n",
    "\\end{equation*}\n",
    "\n",
    "Thus the problem of finding the least squares estimates of $\\theta_0$ and $\\theta_1$ can be written as:\n",
    "\\begin{align*}\n",
    "&\\underset{\\hat\\theta_0,\\: \\hat\\theta_1}{\\text{minimize}} \\: L(\\hat\\theta_0, \\hat\\theta_1) \\\\\n",
    "\\equiv \\quad\n",
    "&\\underset{\\hat\\theta_0,\\: \\hat\\theta_1}{\\text{minimize}} \\:\n",
    "\\sum_{n=1}^{N} \\ell_n(\\hat\\theta_0, \\hat\\theta_1)\n",
    "\\\\\n",
    "\\equiv \\quad\n",
    "&\\underset{\\hat\\theta_0, \\:\\hat\\theta_1}{\\text{minimize}} \\: \\sum_{n=1}^{N} \\left( \\hat\\theta_0 + \\hat \\theta_1 \\:x_n - y_n \\right)^2 \\\\\n",
    "\\equiv \\quad\n",
    "&\\underset{\\hat\\theta}{\\text{minimize}} \\: \\lvert\\lvert \\Phi \\hat\\theta-\\mathbf{Y} \\rvert\\rvert^2_2\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89e479",
   "metadata": {},
   "source": [
    "## (2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d58dd",
   "metadata": {},
   "source": [
    "Write a function called `solve_lr` that takes `XYsamp` as input, constructs $\\Phi$ and $\\mathbf{Y}$, and finds the exact solution to the least squares problem using the formula,\n",
    "\\begin{equation*}\n",
    "\\hat\\theta = (\\Phi^T \\Phi)^{-1}\\Phi^T \\mathbf{Y}\n",
    "\\end{equation*}\n",
    "This function should return the solution as a numpy array of length 2 with $\\hat\\theta_0$ in the zeroth position and $\\hat\\theta_1$ in the first position. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_lr(XYsamp):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['theta_2a'] = solve_lr(XYsamp)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a600bc",
   "metadata": {},
   "source": [
    "# 3. Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f85d16",
   "metadata": {},
   "source": [
    "We will now write an iterative numerical algorithm for solving the least squares problem. We take the objective function of the problem to be:\n",
    "\\begin{equation*}\n",
    "J(\\hat\\theta_0,\\hat\\theta_1) = \\sum_{n=1}^{N} \\left( \\hat\\theta_0 + \\hat \\theta_1 \\:x_n - y_n \\right)^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b9597",
   "metadata": {},
   "source": [
    "## (3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2940417a",
   "metadata": {},
   "source": [
    "Write a function called `nablaJ` that takes `XYsamp`, $\\hat\\theta_0$, and $\\hat\\theta_1$ as inputs, and returns the gradient as a numpy array of length 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72128258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nablaJ(XYsamp, theta0, theta1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['nablaJ_3a_a'] = nablaJ(XYsamp,0.5,-1)\n",
    "result['nablaJ_3a_b'] = nablaJ(XYsamp,1.1,0.6)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecce757",
   "metadata": {},
   "source": [
    "## (3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f6380",
   "metadata": {},
   "source": [
    "Write a function called `gradient_descent` that executes the gradient descent algorithm. This function should take as input \n",
    "\n",
    "+ The dataset `XYsamp`\n",
    "+ the total number of steps to take $K$\n",
    "+ the step size $\\gamma$\n",
    "+ the initial condition Theta0 as a numpy array of length 2. \n",
    "\n",
    "It should return the trajectory as a with shape = `(K,2)`. (8 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(XYsamp,K,gamma,Theta0):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['gd_3b_a'] = gradient_descent(XYsamp,10,0.1,np.array([-0.5,0.5]))\n",
    "result['gd_3b_b'] = gradient_descent(XYsamp,20,0.01,np.array([0.5,-0.5]))\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07150daa",
   "metadata": {},
   "source": [
    "## (3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07442e5f",
   "metadata": {},
   "source": [
    "Complete the `run_gd_on_grid(theta0_grid,theta1_grid,K,gamma)`. This function takes as input\n",
    "+ `theta0_grid` and `theta1_grid`. These are a 5x5 grid of values of $\\hat\\theta_0$ and $\\hat\\theta_1$. \n",
    "+ `K`: the number of steps to take, and\n",
    "+ `gamma`: the step size. \n",
    "\n",
    "The function should return a numpy array with shape (5,5,K,2), where the (i,j,:,:) is a (K,2) trajectory of parameter values. \n",
    "\n",
    "Run the function with $K=200$, $\\gamma=0.2$ and save the result to `trajectories`.\n",
    "\n",
    "Note: The code for creating the 5x5 grid is provided. \n",
    "\n",
    "(8 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5944e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not alter this code. It creates the 5x5 grid of values \n",
    "# that are passed to `run_gd_on_grid`\n",
    "def make_grid(gridN):\n",
    "    theta_0_array = np.linspace(-1,1,gridN)\n",
    "    theta_1_array = np.linspace(-1,1,gridN)\n",
    "    return  np.meshgrid(theta_0_array,theta_1_array)\n",
    "\n",
    "gridN = 5\n",
    "theta0_grid,theta1_grid = make_grid(gridN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gd_on_grid(theta0_grid,theta1_grid,K,gamma):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['grid_3c'] = run_gd_on_grid(theta0_grid,theta1_grid,K=200,gamma=0.2)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37df710",
   "metadata": {},
   "source": [
    "## (3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7f0f5",
   "metadata": {},
   "source": [
    "Complete the function below that plots the error vectors for each of the 25 trajectories in a single plot. The error for each trajectory is an array of length 200, with the $k$'th element computed as:\n",
    "\\begin{equation*}\n",
    "e_k := \\sqrt{ (\\hat\\theta_{0,k}-\\theta_0)^2 + (\\hat\\theta_{1,k}-\\theta_1)^2 } \n",
    "\\end{equation*}\n",
    "Here $k\\in[1,...,K]$ is the gradient descent iteration step. Plot all 25 of them on a single plot with the iteration index on the x axis and the logarithm of the error on the y axis. (8 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f374a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(trajectories):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77adc8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig_3d'] = plot_error(result['grid_3c'])\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aeffaf",
   "metadata": {},
   "source": [
    "## (3e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183c16b",
   "metadata": {},
   "source": [
    "The `plot_quiver` function shown below creates an image of the $\\nabla_\\theta J$ as a vector field and returns the figure handle. \n",
    "\n",
    "Your task is to complete `plot_traj`. This function takes the existing figure handle as input (provided by `plot_quiver`) and should overlay it with the 25 trajectories obtained with gradient descent. Each trajectory should be plotted with a thin red line. `plot_traj` should then return the same figure handle. (6 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quiver():\n",
    "    \n",
    "    gridN = 10\n",
    "    theta0_grid, theta1_grid = make_grid(gridN)\n",
    "    flatgrid = np.reshape([theta0_grid, theta1_grid],(2,gridN**2)).T\n",
    "    UV = np.empty(flatgrid.shape)\n",
    "    for i, (theta0z, theta1z) in enumerate(flatgrid):\n",
    "        UV[i,:] = nablaJ(XYsamp,theta0z, theta1z)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.quiver(flatgrid[:,0], flatgrid[:,1],-UV[:,0],-UV[:,1],scale=30)\n",
    "    \n",
    "    plt.xlabel('theta0',fontsize=15)\n",
    "    plt.ylabel('theta1',fontsize=15)\n",
    "    plt.plot(theta0,theta1,'o',markersize=16)\n",
    "    plt.axis([-1,1,-1,1])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d070a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traj(fig,trajectories):  \n",
    "    plt.figure(fig)\n",
    "       \n",
    "    # add code here...\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be316da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_traj(plot_quiver(),trajectories)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig_3e'] = plot_traj(plot_quiver(),result['grid_3c'])\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead58e37",
   "metadata": {},
   "source": [
    "## (3f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f30ae",
   "metadata": {},
   "source": [
    "Repeat parts (d) and (e) with $\\gamma=0.01$ and $\\gamma=0.7$. (0 pts)\n",
    "Note: This part is not awarded points. It is simply for you to appreciate the effect of the step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "trajectories2 = run_gd_on_grid(theta0_grid,theta1_grid ,K=200,gamma=0.01)\n",
    "result['fig_3fA_phase'] = plot_traj(plot_quiver(),trajectories2)\n",
    "result['fig_3fA_error'] = plot_error(trajectories2)\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15fc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "trajectories3 = run_gd_on_grid(theta0_grid,theta1_grid ,K=200,gamma=0.7)\n",
    "result['fig_3fB_phase'] = plot_traj(plot_quiver(),trajectories3)\n",
    "result['fig_3fB_error'] = plot_error(trajectories3)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f24ab1",
   "metadata": {},
   "source": [
    "# 4. Additive cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24640461",
   "metadata": {},
   "source": [
    "The deliverable for this part is a single plot is in the $\\theta_0, \\theta_1$ plane. The limits should be from -1 to 1 along both axes, as in previous parts. The plot should have these elements. (10 pts)\n",
    "\n",
    "+ For each sample $n$, draw a thin black line in the parameter space corresponding to $\\ell_n=0$. There should be a total of $N=40$ lines. \n",
    "+ Place a small dot at the intersection of every line. There will be a total of $N(N-1)/2$ such dots. Briefly explain the interpretation of these intersections. \n",
    "+ Plot a large dot at the location of the true parameter values. \n",
    "+ Overylay one of the gradient descent trajectories from part 3.\n",
    "\n",
    "Save the handle of the figure in the variable `fig4`. This will be added to the results dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19835332",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c498e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig4'] = fig4\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4670ba9",
   "metadata": {},
   "source": [
    "# 5. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c68bd1",
   "metadata": {},
   "source": [
    "## 5(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad0f50",
   "metadata": {},
   "source": [
    "(10 pts) Code stochastic gradient descent. Complete the function `SGD` below. This function takes as arguments \n",
    "+ the dataset `XYsamp`, \n",
    "+ the step size $\\gamma$ and \n",
    "+ the number of epochs to run. \n",
    "\n",
    "`SGD` function should\n",
    "\n",
    "+ randomly choose the initial condition with uniform probability from $[-1,1]\\times[-1,1]$\n",
    "+ use batches of size 1,\n",
    "+ draw samples without replacement.\n",
    "\n",
    "The function should return the parameter trajectory. \n",
    "\n",
    "\n",
    "Run SGD with $\\gamma=0.1$ and 10 epochs. Recreate the plot from part 4 but using this SGD trajectory instead of GD. Save the figure handle as `fig5a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(XYsamp,gamma,epochs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895928a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5a = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3902c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig5a'] = fig5a\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce74ae9",
   "metadata": {},
   "source": [
    "## 5(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4ab5c",
   "metadata": {},
   "source": [
    "Make the same plot with $\\gamma=0.01$ and $\\gamma=0.4$. Save the figure handles respectively as `fig5b1` and `fig5b2`. (6 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21882b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5b1 = plt.figure()\n",
    "fig5b2 = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig5b1'] = fig5b1\n",
    "result['fig5b2'] = fig5b2\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd92d2",
   "metadata": {},
   "source": [
    "## 5(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbda051",
   "metadata": {},
   "source": [
    "Comment on the pros and cons of SGD with respect to GD. Save your comments in a string called `comment`. (6 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['comment'] = comment\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3c1d9",
   "metadata": {},
   "source": [
    "---\n",
    "## Do not modify below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}.pickle'.format(\"_\".join([str(sid) for sid in result['SIDs']])),'wb') as file:\n",
    "    pickle.dump(result,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
